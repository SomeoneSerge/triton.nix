# Nix rules for the [triton inference server](https://github.com/triton-inference-server/server)

## Status

- [x] [microsoft/onnxruntime](https://github.com/microsoft/onnxruntime)
    - [ ] Build as is, using upstream's script
    - [ ] Wrap all submodules separately, discard the `build.py`
- [ ] [onnxruntime_backend](https://github.com/triton-inference-server/onnxruntime_backend)
- [ ] ...
- [ ] [server](https://github.com/triton-inference-server/server)
